\documentclass[12pt,a4paper]{article}
\usepackage[margin=1.25in]{geometry}
\usepackage{fancyhdr} % fancy header
\pagestyle{fancy} % so fancy
\usepackage[russian,english]{babel} % for russian letters
\usepackage{tipa} % for IPA symbols
\usepackage[round]{natbib} % bibliography
\usepackage{graphicx} % for importing graphics / figures
\usepackage{booktabs} % publication-worthy tables
\usepackage{adjustbox} % makes tables fit nicely on the page
\usepackage{hyperref}

\lhead{Josh Meyer}
\rhead{Cover Letter: Apple (Siri Group)}
\cfoot{} %% make empty to get rid of the page number %% \cfoot{Page \thepage}
\renewcommand{\footrulewidth}{0.4pt} %% this puts a fancy line at the footer



%
% mozilla
% NSF
% Interspeech
%

\begin{document}


\subsection*{Who I am}

Iâ€™m a PhD candidate passionate about Machine Learning and open-source language technologies.

My educational background is in Computational Linguistics, Theoretical Linguistics, Natural Language Processing, Statistics, and Cognitive Science. My PhD thesis focuses on Speech Technology, and Automatic Speech Recognition in particular. I work to develop approaches for training more robust Deep Neural Networks for Speech Recognition, using Multi-Task Learning and Transfer Learning.

My research is linguistically informed, but based in machine learning methods.


\subsection*{What I do}

I work on Automatic Speech Recognition. Currently, I am a National Science Foundation Research Fellow as well as a Research Intern at the Mozilla Machine Learning Research Group.

My PhD research investigates Multi-Task approaches for Acoustic Modeling (in the hybrid DNN-HMM framework, using Kaldi). Specifically, I look at auxiliary task creation for use in Multi-Task training, where little human knowledge is required to create the tasks. The extra tasks are then used during DNN acoustic model parameter search (i.e. during backprop).

Currently, I work on Transfer Learning techniques for adaptation of end-to-end ASR models. Specifically, I maintain the \texttt{transfer-learning} branch of Mozilla's DeepSpeech. My main interest is to enable easy transfer approaches for low-resource language / domain adaptation.


\subsection*{Checking off boxes}

\begin{enumerate}

\item GitHub: \href{https://github.com/JRMeyer}{JRMeyer}
    
\item Speech Technology Blog: \href{http://jrmeyer.github.io}{jrmeyer.github.io}

\item Graduate Coursework: Applied NLP // Statistical NLP // Intro to Machine Learning // Speech Language Technology // Regression Analysis (A + B)
  
\item Multi-Task ASR Research: \href{https://github.com/JRMeyer/multi-task-kaldi}{Multi-Task Kaldi}
  
\item DeepSpeech + Transfer Learning: \href{https://github.com/mozilla/DeepSpeech/tree/transfer-learning}{Transfer Learning branch of DeepSpeech}
  
\item TensorFlow skills: \href{http://jrmeyer.github.io/machinelearning/2016/02/01/TensorFlow-Tutorial.html}{The Flow of TensorFlow}
  
\item Math skills: \href{http://jrmeyer.github.io/machinelearning/2017/08/18/mle.html}{MLE for Gaussians tutorial}
  
\end{enumerate}

\vspace{1cm}

\begin{center}
\textit{Thank you for your time and consideration.}  
\end{center}

\end{document}



 
